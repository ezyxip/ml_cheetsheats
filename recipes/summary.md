## Общая договорённость по формату шпор

Для всех файлов можно держать один и тот же шаблон разделов:

1. **Когда применять** (коротко: тип задачи, тип данных).
2. **Алгоритм шагов** (по пунктам).
3. **Код‑шаблон** (минимальный рабочий пример).
4. **Варианты и настройки** (альтернативы, параметры).
5. **Чек‑лист и подводные камни**.

---

## 00\_principles\_and\_pipeline.md — Принципы и общий ML‑пайплайн

Что внутри:

- Краткий чек‑лист разумного ML:
  - обоснованность, жизнеспособность, надёжность, интерпретируемость.
- Общая схема пайплайна:
  - загрузка данных → EDA → препроцессинг → фичи → выбор модели → валидация → тюнинг → финальная модель → интерпретация.
- Bias/Variance:
  - High Bias (недообучение) vs High Variance (переобучение), Bias–Variance tradeoff.
- Простые vs сложные модели:
  - линейная регрессия / мелкие деревья vs ансамбли / бустинг / нейросети.
- Где использовать:
  - кросс‑валидацию (CV), отложенную выборку (test set).
- Типовые ошибки:
  - data leakage, неправильная валидация, метрика не соответствует задаче.

---

## 01\_project\_structure\_and\_reproducibility.md — Структура проекта и воспроизводимость

Что внутри:

- Шаблон структуры проекта:
  - `data/`, `notebooks/`, `src/`, `models/`, `reports/`, `configs/`.
- Воспроизводимость:
  - сидирование (`np.random.seed`, `random.seed`, `sklearn`, `torch`/`tf` по необходимости).
- Управление зависимостями:
  - `requirements.txt`, `environment.yml`.
- Как сохранять:
  - версии данных, версию кода/модели, параметры обучения.

---

## 02\_data\_loading\_and\_eda.md — Загрузка данных и базовый EDA

Что внутри:

- Рецепты загрузки:
  - `pd.read_csv`, Excel, parquet, разделители, кодировки.
- Базовый обзор:
  - `.head()`, `.info()`, `.describe()`, `dtypes`, размеры датасета (число объектов, признаков).
- Поиск:
  - пропусков, дубликатов, распределений признаков.
- Быстрый визуальный EDA:
  - гистограммы, barplot для категорий,
  - boxplot для выбросов,
  - scatter plot для пар признаков и таргета,
  - heatmap корреляций (Корреляция Пирсона).
- Чек‑лист:
  - типы задач (регрессия/классификация/временные ряды), таргет.

---

## 03\_missing\_values\_and\_imputation.md — Пропуски: стратегии и рецепты

Что внутри:

- Варианты обработки:
  - логическая замена (например, 0/“Unknown”),
  - удаление строк/столбцов (drop),
  - простая импутация: среднее, медиана, мода (SimpleImputer),
  - KNNImputer,
  - MICE / IterativeImputer.
- Практические паттерны:
  - как делать `.fit` только на train, `.transform` на train+test.
- Как сравнивать:
  - влияние разных стратегий на распределения (в т.ч. через KL‑дивергенцию).
- Чек‑лист:
  - не использовать таргет в импутации,
  - раздельный препроцессинг для train/test.

---

## 04\_categorical\_encoding.md — Категории и кодирование

Что внутри:

- Определение типов категорий:
  - порядковые vs номинальные.
- Основные энкодеры:
  - Ordinal Encoding (в т.ч. через mapping),
  - One‑Hot Encoding (OHE),
  - Label Encoding,
  - Target / Mean Encoding (с сглаживанием),
  - Binary Encoding (через `category_encoders`).
- Проклятие размерности:
  - как OHE раздувает пространство, когда это критично.
- Dummy Trap и мультиколлинеарность с OHE.
- Чек‑лист:
  - fit энкодеров только на train,
  - утечка в target encoding и как её избегать (CV‑схема).

---

## 05\_outliers\_and\_anomalies.md — Выбросы и аномалии

Что внутри:

- Классические методы:
  - IQR (межквартильный размах),
  - Z‑score.
- Визуализация:
  - boxplot (“ящик с усами”),
  - логарифмирование признаков для “тяжёлых хвостов”.
- Алгоритмы детекции аномалий:
  - Isolation Forest,
  - One‑Class SVM,
  - DBSCAN (eps, minPts, core/border/noise).
- Workflow:
  - когда убирать выбросы,
  - когда помечать как аномалии и обучать модель.

---

## 06\_feature\_engineering\_general.md — Общий Feature Engineering

Что внутри:

- Базовый подход:
  - baseline (простая модель без сложных фичей).
- Типы генерации признаков:
  - формулы предметной области,
  - арифметические комбинации (суммы, отношения),
  - агрегаты по группам (`groupby` — mean, sum, count, std),
  - биннинг числовых признаков.
- Нелинейные преобразования:
  - `log`, `sqrt`, `exp`.
- Внешние данные:
  - как “подмерджить” external data по ключу.
- Чек‑лист:
  - не использовать будущее для построения признаков,
  - проверять важность новых фич (feature importance).

---

## 07\_feature\_engineering\_time\_series.md — Фичи для временных рядов

Что внутри:

- Корректная работа с временными рядами:
  - сортировка по времени,
  - train/test split “по времени”,
  - TimeSeriesSplit.
- Признаки:
  - лаги (Lags),
  - разности (differences),
  - скользящие статистики (rolling mean/std),
  - сезонность (месяц, день недели, час и т.д.).
- Чек‑лист:
  - строгий запрет утечки из будущего,
  - особенности масштабирования и кодирования для временных задач.

---

## 08\_scaling\_multicollinearity\_pca.md — Масштабирование, мультиколлинеарность, PCA

Что внутри:

- Масштабирование:
  - когда нужно и когда нет,
  - StandardScaler, MinMaxScaler, RobustScaler — примеры и типичные случаи.
- Мультиколлинеарность:
  - heatmap корреляций,
  - VIF (Variance Inflation Factor).
- Борьба с ней:
  - удаление признаков,
  - регуляризация: Ridge (L2), Lasso (L1), ElasticNet.
- Снижение размерности:
  - PCA: как применить, как выбирать число компонент.
- Связь с “проклятием размерности”.

---

## 09\_splits\_validation\_and\_leakage.md — Разбиения, валидация и утечка данных

Что внутри:

- Базовые разбиения:
  - `train_test_split` (с `stratify` для классификации),
  - отложенный test set.
- Кросс‑валидация:
  - k‑Fold, Stratified k‑Fold,
  - GroupKFold / GroupSplit,
  - TimeSeriesSplit.
- Как выбирать схему CV под задачу.
- Data Leakage:
  - типовые кейсы утечки (масштабирование, encoding, импутация на всём датасете),
  - как организовать пайплайны, чтобы этого избежать.

---

## 10\_imbalanced\_classes.md — Дисбаланс классов: рецепты

Что внутри:

- Как обнаружить дисбаланс.
- Метрики для несбалансированных данных:
  - ROC‑AUC, PR‑AUC, Precision, Recall, F1‑score.
- Методы борьбы:
  - `class_weight='balanced'`,
  - oversampling (SMOTE),
  - undersampling (RandomUnderSampler),
  - изменение порога (threshold).
- Использование `imblearn`:
  - Pipeline со SMOTE/RandomUnderSampler.

---

## 11\_model\_selection\_and\_baselines.md — Выбор моделей и базовые решения

Что внутри:

- Baseline:
  - DummyRegressor/DummyClassifier,
  - среднее/медиана/мода для регрессии,
  - “всегда предсказывать самый частый класс” для классификации.
- Как выбирать модель:
  - линейность/нелинейность зависимости,
  - размер датасета и число признаков,
  - требуемая интерпретируемость.
- Обзор моделей:
  - линейные (LinReg, Logistic),
  - KNN, Naive Bayes, SVM,
  - деревья, RandomForest,
  - градиентный бустинг (XGBoost, LightGBM, CatBoost),
  - кратко — плюсы/минусы.

---

## 12\_training\_and\_hyperparameter\_tuning.md — Обучение и тюнинг гиперпараметров

Что внутри:

- Базовый шаблон:
  - `.fit`, `.predict`, `.predict_proba`.
- Кросс‑валидация в тюнинге:
  - `GridSearchCV`, `RandomizedSearchCV`,
  - пример с `KFold`/`StratifiedKFold`.
- BayesOpt:
  - упоминание библиотек (например, `skopt` / `optuna`),
  - общая схема использования.
- Типовые сетки гиперпараметров:
  - для RF, XGBoost, LightGBM, CatBoost, SVM, KNN.
- Как выбирать метрику для `scoring`.

---

## 13\_metrics\_regression\_and\_diagnostics.md — Регрессия: метрики и диагностика

Что внутри:

- Метрики:
  - MAE, MSE, RMSE, MAPE, SMAPE, R² — формулы + вызовы в sklearn.
- Диагностика:
  - график Predicted vs Actual,
  - графики остатков (Residuals vs Predicted),
  - проверка гетероскедастичности.
- Как интерпретировать:
  - что значит хорошее/плохое значение, как сравнивать модели.

---

## 14\_metrics\_classification\_and\_diagnostics.md — Классификация: метрики и диагностика

Что внутри:

- Метрики:
  - Accuracy,
  - Precision, Recall, F1‑score,
  - ROC‑AUC, PR‑AUC.
- Визуализация:
  - ROC‑кривая (TPR vs FPR),
  - Precision‑Recall‑кривая.
- Матрица ошибок (confusion matrix).
- Работа с порогом:
  - как менять порог и строить графики зависимости метрик от порога.
- Особый фокус на дисбаланс классов.

---

## 15\_model\_interpretation.md — Интерпретация моделей

Что внутри:

- Глобальная интерпретация:
  - feature importance для деревьев/бустинга,
  - коэффициенты линейных моделей,
  - permutation importance.
- Локальная интерпретация:
  - SHAP: общий принцип,
  - примеры для CatBoost/XGBoost/LightGBM/RandomForest.
- Виды SHAP‑графиков:
  - summary plot, dependence plot, force plot.
- Как использовать интерпретацию:
  - проверка здравого смысла,
  - поиск утечек и странных фичей.

---

## 16\_pipelines\_and\_columntransformer.md — Полный sklearn‑пайплайн

Что внутри:

- Шаблон:
  - разделение признаков на числовые/категориальные,
  - `ColumnTransformer` для разных веток препроцессинга,
  - `Pipeline` (импутация → масштабирование → кодирование → модель).
- Как совмещать:
  - тюнинг гиперпараметров модели и препроцессинга в одном `GridSearchCV`.
- Примеры для:
  - регрессии,
  - классификации,
  - временных рядов (с TimeSeriesSplit).

---

## 17\_visualizations\_recipes.md — Общие рецепты визуализаций

Что внутри:

- Гистограммы, KDE, boxplot — распределения и выбросы.
- Scatter plot, pairplot — проверка линейности/нелинейности.
- Heatmap корреляций.
- Визуализация групп:
  - barplot/boxplot по категориям.
- Шаблоны для matplotlib/seaborn:
  - быстрые куски кода “скопировал‑вставил”.

(Часть этого пересекается с EDA и диагностикой, но удобно иметь отдельный “словарь” графиков.)

---

## 18\_streamlit\_app\_recipes.md — Быстрые приложения на Streamlit

Что внутри:

- Минимальный шаблон приложения:
  - структура файла `app.py` и запуск `streamlit run app.py`.
- Рецепт “онлайн‑предсказания”:
  - загрузка обученной модели (`joblib`/`pickle`),
  - форма ввода признаков пользователем,
  - вывод предсказаний и метрик.
- Рецепт “анализ загруженного файла”:
  - `st.file_uploader`, чтение CSV,
  - вывод EDA (таблица, графики),
  - применение модели к загруженному датасету.
- Визуализация интерпретации:
  - простое отображение feature importance / SHAP‑графиков.

---

## 19\_formulas\_and\_definitions.md — Формулы и определения для теории

Что внутри:

- Формулы:
  - метрики (MAE/MSE/…),
  - L1/L2 регуляризация,
  - базовые вещи для Bias/Variance,
  - KL‑дивергенция (в простом виде).
- Краткие определения:
  - обоснованная модель, жизнеспособная/надёжная/интерпретируемая,
  - недообучение/переобучение,
  - Data Leakage,
  - проклятие размерности и т.д.
- Очень сжатые ответы “в одно‑две предложения” для экзамена.
