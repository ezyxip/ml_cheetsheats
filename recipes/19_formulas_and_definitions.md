```markdown
# 19. Формулы и определения (шпаргалка для теории)

---

## 0. Обозначения

- \(y_i\) — истинное значение таргета для объекта i  
- \(\hat{y}_i\) — предсказание модели  
- \(n\) — число объектов  
- \(p\) — число признаков  
- \(\bar{y} = \frac{1}{n}\sum y_i\) — среднее по таргету  

---

## 1. Метрики регрессии — формулы

### 1.1. MAE — Mean Absolute Error

\[
\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
\]

`sklearn`:
```python
from sklearn.metrics import mean_absolute_error
mae = mean_absolute_error(y_true, y_pred)
```

---

### 1.2. MSE — Mean Squared Error

\[
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]

```python
from sklearn.metrics import mean_squared_error
mse = mean_squared_error(y_true, y_pred)
```

---

### 1.3. RMSE — Root Mean Squared Error

\[
\text{RMSE} = \sqrt{\text{MSE}} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}
\]

```python
rmse = mean_squared_error(y_true, y_pred, squared=False)
```

---

### 1.4. MAPE — Mean Absolute Percentage Error

\[
\text{MAPE} = \frac{100\%}{n} \sum_{i=1}^{n} \left|\frac{y_i - \hat{y}_i}{y_i}\right|
\]

(при \(y_i \neq 0\))

```python
from sklearn.metrics import mean_absolute_percentage_error
mape = mean_absolute_percentage_error(y_true, y_pred) * 100
```

---

### 1.5. SMAPE — Symmetric MAPE (одна из форм)

\[
\text{SMAPE} = \frac{100\%}{n} \sum_{i=1}^{n} 
\frac{|y_i - \hat{y}_i|}{\left(|y_i| + |\hat{y}_i|\right) / 2}
\]

(реализация вручную)

---

### 1.6. R² — коэффициент детерминации

\[
R^2 = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}
\]

```python
from sklearn.metrics import r2_score
r2 = r2_score(y_true, y_pred)
```

---

## 2. Метрики классификации — формулы

Для бинарной классификации:

- TP — True Positives  
- FP — False Positives  
- TN — True Negatives  
- FN — False Negatives  

### 2.1. Accuracy

\[
\text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
\]

```python
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_true, y_pred)
```

---

### 2.2. Precision, Recall

\[
\text{Precision} = \frac{TP}{TP + FP}
\]

\[
\text{Recall} = \frac{TP}{TP + FN}
\]

```python
from sklearn.metrics import precision_score, recall_score
precision = precision_score(y_true, y_pred)
recall    = recall_score(y_true, y_pred)
```

---

### 2.3. F1‑score

\[
F1 = 2 \cdot \frac{\text{Precision} \cdot \text{Recall}}{\text{Precision} + \text{Recall}}
\]

```python
from sklearn.metrics import f1_score
f1 = f1_score(y_true, y_pred)
```

---

### 2.4. ROC‑AUC, PR‑AUC (идея)

- ROC‑AUC — площадь под ROC‑кривой (TPR vs FPR при разных порогах).
- PR‑AUC (Average Precision) — площадь под Precision‑Recall кривой.

Формально — интегралы по кривым; на практике считаются численно.

```python
from sklearn.metrics import roc_auc_score, average_precision_score

roc_auc = roc_auc_score(y_true, y_proba)
pr_auc  = average_precision_score(y_true, y_proba)
```

---

## 3. Регуляризация (L1 / L2)

Пусть модель — линейная регрессия:

\[
L_{\text{MSE}}(w) = \frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y}_i)^2
\]

### 3.1. L2 (Ridge)

\[
L_{\text{Ridge}}(w) = L_{\text{MSE}}(w) + \lambda \sum_{j=1}^{p} w_j^2
\]

- штрафуем **квадраты** весов → делаем их маленькими, но не нулевыми.

---

### 3.2. L1 (Lasso)

\[
L_{\text{Lasso}}(w) = L_{\text{MSE}}(w) + \lambda \sum_{j=1}^{p} |w_j|
\]

- штрафуем **модули** весов → часть весов становится ровно нулём (отбор признаков).

---

### 3.3. ElasticNet

\[
L_{\text{EN}}(w) = L_{\text{MSE}}(w) 
+ \lambda \left( \alpha \sum_{j=1}^{p} |w_j| + (1 - \alpha) \sum_{j=1}^{p} w_j^2 \right)
\]

- комбинация L1 и L2.

---

## 4. Bias–Variance (Смещение–Дисперсия)

Пусть:
- \(f(x)\) — истинная функция,  
- \(\hat{f}(x)\) — предсказание модели, зависящее от обучающей выборки (случайная величина),  
- \(\varepsilon\) — шум, дисперсия \(\sigma^2\).

**Разложение MSE** (ожидание по выборкам):

\[
\mathbb{E}\left[(y - \hat{f}(x))^2\right] 
= \underbrace{\left(\mathbb{E}[\hat{f}(x)] - f(x)\right)^2}_{\text{Bias}^2}
+ \underbrace{\mathbb{V}[\hat{f}(x)]}_{\text{Variance}}
+ \underbrace{\sigma^2}_{\text{Noise}}
\]

- **High Bias (недообучение)**: модель слишком простая → большое \(\text{Bias}^2\).
- **High Variance (переобучение)**: модель слишком сложна�� → большая \(\text{Variance}\).

---

## 5. KL‑дивергенция (Kullback–Leibler)

Для дискретных распределений \(P\) и \(Q\) на одном и том же множестве:

\[
D_{\text{KL}}(P \,\|\, Q) = \sum_{i} P(i) \log \frac{P(i)}{Q(i)}
\]

- меряет, насколько распределение \(Q\) “отличается” от \(P\);
- \(D_{KL} \ge 0\), и = 0 тогда и только тогда, когда \(P = Q\) почти везде;
- несимметрична: \(D_{KL}(P\|Q) \neq D_{KL}(Q\|P)\).

---

## 6. Краткие определения (1–2 предложения)

Формат: **Термин** — определение.

### 6.1. Принципы и качества модели

**Обоснованная модель** — модель, у которой есть понятная мотивация выбора признаков, алгоритма и метрик, учитывающая предметную область и ограничения реального применения.

**Жизнеспособная модель** — модель, которая не только хорошо работает на валидации, но и удовлетворяет ограничения по времени, памяти, интерпретируемости, обновляемости и т.п.

**Надёжная модель** — модель, чьи предсказания стабильны при небольших изменениях данных, устойчива к шуму и сдвигам распределения, без резких провалов качества.

**Интерпретируемая модель** — модель, для которой человек может понять, какие признаки и как влияют на предсказания (через простую структуру или методы объяснения вроде SHAP).

---

### 6.2. Недообучение, переобучение, trade‑off

**Недообучение (High Bias)** — модель слишком простая, не улавливает структуру данных, даёт высокую ошибку и на train, и на validation.

**Переобучение (High Variance)** — модель слишком сложная, подстраивается под шум в train, даёт низкую ошибку на train и заметно худшую на validation/test.

**Bias–Variance Tradeoff** — компромисс: уменьшая смещение (делая модель сложнее), обычно увеличиваем дисперсию, и наоборот; цель — найти баланс с минимальной суммарной ошибкой.

---

### 6.3. Data Leakage и валидация

**Data Leakage (утечка данных)** — ситуация, когда при обучении/препроцессинге используется информация из validation/test/будущего (или напрямую из таргета), что приводит к завышенным метрикам и провалу на реальных данных.

**Кросс‑валидация (Cross‑Validation)** — метод оценки модели, при котором данные многократно разбиваются на train/validation фолды для более устойчивой оценки качества и подбора гиперпараметров.

**k‑Fold CV** — данные делятся на k частей, каждая по очереди становится validation, остальные — train; итоговая метрика — среднее по фолдам.

**Stratified k‑Fold** — вариант k‑Fold, при котором в каждом фолде сохраняется распределение классов, полезен для классификации и дисбаланса.

**GroupKFold** — k‑Fold с группами, гарантирующий, что объекты одной группы (user_id и т.п.) не попадают и в train, и в validation одновременно.

**TimeSeriesSplit** — схема CV для временных рядов, где train‑фолд всегда “раньше” во времени, чем validation‑фолд (без перемешивания).

---

### 6.4. Проклятие размерности и размерность признаков

**Проклятие размерности** — эффект, при котором с ростом числа признаков экспоненциально растёт требуемый объём данных, а расстояния между точками “выравниваются”, что ухудшает работу многих алгоритмов (особенно KNN/SVM/методов на расстояниях).

**Снижение размерности** — преобразование исходных признаков в меньшее число новых (например, PCA), чтобы уменьшить шум, мультиколлинеарность и эффект проклятия размерности.

---

### 6.5. Регуляризация и гиперпараметры

**Регуляризация** — добавление штрафа к функции потерь (обычно на величину весов), чтобы уменьшить сложность модели и бороться с переобучением.

**L1‑регуляризация (Lasso)** — штраф на сумму модулей весов, зануляет часть весов и тем самым отбирает признаки.

**L2‑регуляризация (Ridge)** — штраф на сумму квадратов весов, делает веса меньше по модулю, но редко зануляет полностью.

**Гиперпараметры** — параметры алгоритма, задаваемые “снаружи” (глубина дерева, C и gamma для SVM, learning_rate и n_estimators для бустинга), которые не обучаются по градиенту и подбираются через поиск по сетке/случайный/байесовский поиск.

---

### 6.6. Метрики и дисбаланс

**Accuracy** — доля правильных предсказаний; хороша при примерно сбалансированных классах, но вводит в заблуждение при сильном дисбалансе.

**Precision** — доля истинных позитивов среди всех предсказанных позитивов; показывает, насколько “чистые” наши позитивные предсказания.

**Recall** — доля найденных позитивов среди всех истинных позитивов; показывает, насколько хорошо модель “находит” интересующий класс.

**F1‑score** — гармоническое среднее Precision и Recall, баланс между “не пропустить” и “не задавить лишним шумом”.

**ROC‑AUC** — вероятность, что модель поставит больший скор случайному позитиву, чем случайному негативу; устойчивая метрика при разных порогах, но при сильном дисбалансе PR‑AUC часто информативнее.

**PR‑AUC (Average Precision)** — площадь под кривой Precision‑Recall, лучше отражает качество модели на редком позитивном классе.

---

### 6.7. Признаки, фичи, Feature Engineering

**Feature Engineering** — процесс создания/преобразования признаков (суммы, отношения, агрегации, лаги и т.д.) для усиления сигнала в данных и улучшения качества модели.

**Мультиколлинеарность** — сильная линейная взаимосвязь между признаками; в линейных моделях приводит к нестабильным коэффициентам и сложной интерпретации.

**Важность признаков (feature importance)** — мера вклада признака в качество модели; может оцениваться по деревьям (Gini/gain), permutation importance или SHAP.

---

### 6.8. Временные ряды

**Временной ряд** — последовательность наблюдений, упорядоченная по времени, где важен не только уровень признаков, но и порядок/динамика.

**Лаги (lags)** — значения признака или таргета в прошлые моменты времени (t−1, t−2, …), используемые в качестве признаков для предсказания будущего.

**Гетероскедастичность** — ситуация, когда дисперсия ошибок (остатков) зависит от уровня предсказаний или признаков; на графике “остатки vs предсказания” выглядит как “веер”.

---

Этого набора формул и определений обычно достаточно, чтобы коротко и по делу отвечать на теоретические вопросы по ML на экзамене.
```