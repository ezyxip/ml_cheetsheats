# ШПОРА: Выбор моделей и метрик, обучение и интерпретация (Лекция 6)

## 1) Что у тебя уже есть перед моделированием
Перед тем как “выбирать модель”, убедись, что базовая предобработка сделана и **не ломает валидацию**:
- сплит train/test (или CV) сделан правильно (стратификация/время/группы)
- пропуски/кодирование/скейлинг/агрегации делались без утечек (fit только на train)
- выбросы/аномалии обработаны осмысленно (не “вырезали реальность”)

---

## 2) Практический чек-лист выбора модели (что реально влияет)

### 2.1 Тип зависимости (линейность/нелинейность)
**Как быстро проверить:**
- scatter plot таргета vs ключевые признаки
- корреляция Пирсона (теплокарта), но помни: Пирсон ловит в основном линейность

**Если зависимость близка к линейной или данные разреженные:**
- Linear/Ridge/Lasso/ElasticNet
- Linear SVM
Плюсы: быстрые, устойчивые, интерпретируемые.

**Если зависимость сложная/нелинейная:**
- деревья/RandomForest/градиентный бустинг по деревьям (часто лучший “рабочий” старт)
- нейросети (когда много данных и есть смысл)

### 2.2 Размер датасета (важно для времени и рисков)
Из конспекта (как правило-подсказка на практике):
- **< 5k**: линейные, деревья, ансамбли, SVM; нейросети обычно невыгодны
- **5–200k**: ансамбли, иногда KNN (если размерность небольшая)
- **> 200k**: нейросети чаще становятся оправданными; KNN/SVM обычно тяжело

Практика: если ограничен временем, выбирай **модель, которая даст хороший baseline быстро** (часто это CatBoost/LightGBM/XGBoost или RandomForest, если нет бустинга).

### 2.3 Размерность признаков
- **> 200 признаков / разреженные данные** (тексты, OHE с множеством категорий):
  - линейные модели, логистическая регрессия, линейный SVM, наивный Байес
- **≤ 200 признаков**: можно пробовать почти всё

### 2.4 Интерпретируемость (обязательное требование или “желательно”?)
- Если нужна “железная” интерпретация: линейные модели (коэффициенты), простые деревья.
- Если качество важнее: ансамбли/бустинг/NN, но **интерпретацию добираем SHAP’ом**.

### 2.5 Цена гиперпараметров
- Нейросети и сложные SVM могут “съесть” время на тюнинг.
- На экзамене/в проекте: сначала простая модель, потом усложнение.

---

## 3) Выбор метрики (самое прикладное)
Метрика выбирается **до обучения** и должна отражать “что считается ошибкой”.

### 3.1 Регрессия: что когда брать
- **MAE** — простая интерпретация (“в среднем ошибаемся на X единиц”), устойчива к выбросам.
- **MSE/RMSE** — сильнее штрафуют большие ошибки (полезно, если большие промахи очень плохи).
- **MAPE/SMAPE** — когда важна относительная ошибка (в %), но MAPE ломается при значениях около нуля.
- **R²** — “доля объясненной дисперсии”, удобно для сравнения, но не всегда отражает бизнес-цену ошибок.

Практическая памятка: если сомневаешься — начинай с **MAE + RMSE** вместе.

### 3.2 Классификация: что важно при дисбалансе
- Accuracy часто бесполезна при дисбалансе.
- В конспекте: **при дисбалансе accuracy и ROC-AUC — плохой выбор**. (На практике ROC-AUC часто используют, но если нужно качество по “редкому классу”, обычно полезнее PR-AUC/F1/Recall.)

**Выбирай по цене ошибок:**
- Важно “не тревожить зря” → **Precision** выше
- Важно “не пропустить” → **Recall** выше
- Нужен баланс → **F1**

Практика: почти всегда держат **2–3 метрики**: например `F1 + Recall + PR-AUC` (для дисбаланса) или `ROC-AUC + F1`.

---

## 4) Как правильно обучать и сравнивать модели (процесс)
Рабочая схема без магии:

1) **Фиксируешь пайплайн данных** (один вариант препроцессинга).
2) **Фиксируешь модель** (baseline) и стартовые гиперпараметры.
3) **Выбираешь схему валидации** (см. ниже).
4) **Делаешь CV**, получаешь среднюю метрику и разброс.
5) **Тюнишь гиперпараметры** (grid/random/bayes — не принципиально для шпоры).
6) Берёшь **лучшую по CV**.
7) **Финальная проверка один раз на test**.

Ключевая мысль: нельзя “подглядывать” в test много раз — это скрытая утечка через выбор.

---

## 5) Кросс-валидация: какой вариант куда
- **k-Fold** — стандарт для регрессии/классификации без особых условий.
- **Stratified k-Fold** — классификация, особенно при дисбалансе (сохраняет доли классов).
- **TimeSeriesSplit** — временные ряды (чтобы не обучаться на будущем).
- **Group Split** (в конспекте упомянут ранее, но логика та же) — если есть группы (один клиент/пациент встречается много раз).

Практический выбор:
- классификация + дисбаланс → StratifiedKFold
- временные данные → TimeSeriesSplit
- “много записей на одного объекта” → GroupKFold/GroupShuffleSplit

---

## 6) Интерпретация модели: что реально делать
### 6.1 Feature Importance (деревья/ансамбли)
- Быстро понять, какие признаки модель использует.
- Использовать как диагностику: если “важный” признак выглядит как утечка (например, постфактум-данные) — тревога.

### 6.2 SHAP (универсальная интерпретация)
- Дает вклад признаков:
  - **глобально** (что важно в целом)
  - **локально** (почему конкретному объекту такой прогноз)
- Практическая польза:
  - найти утечки/мусорные признаки,
  - выкинуть слабые признаки и упростить модель,
  - объяснить решение бизнесу/преподавателю.

После интерпретации часто делают цикл:
1) убрали мусор/утечку  
2) переобучили  
3) проверили метрики снова

---

## 7) Быстрый “экзаменационный” набор ответов
- **Как выбираешь модель?** По типу зависимостей, размеру данных, размерности признаков, требованиям к интерпретации и сложности тюнинга.
- **Как выбираешь метрику?** До обучения, исходя из цены ошибок и дисбаланса; обычно использую несколько метрик.
- **Как честно сравнивать модели?** Одинаковый пайплайн данных + CV (правильного типа) + test один раз в конце.
- **Как интерпретировать сложную модель?** Feature importance (деревья) и SHAP (почти для любых).
