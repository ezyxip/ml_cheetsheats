# ШПОРА: Feature Engineering, Scaling, Мультиколлинеарность (Лекция 5)

## 1) Генерация новых признаков (Feature Engineering)
Идея: из исходных столбцов сделать **более информативные**. Часто это дает больший прирост, чем смена модели.

### Практический алгоритм
1) Сделай **baseline** на сырых признаках.  
2) Добавляй признаки пакетами (по смыслу) и **меряй прирост на валидaции**.  
3) Если прироста нет/хуже — откатывай пакет.

### Самые полезные типы генерации
**A. Формулы предметной области**
- Пример: `ratio = feature1 / feature2`, `margin = revenue - cost`.
- Плюс: часто наиболее “сильные” признаки и хорошо объяснимы.

**B. Арифметические комбинации**
- `+, -, *, /, x^2` и т.д.
- Практически: полезно для линейных моделей (они сами нелинейность не поймают).

**C. Агрегации по группам (groupby)**
- Пример: средний чек по клиенту, число заказов по пользователю.
- Очень сильный класс признаков, но **главная ловушка — утечка** (см. ниже).

**D. Нелинейные преобразования**
- `log`, `sqrt`, `exp` и т.п.
- Практически:  
  - `log(1+x)` для “длинных хвостов” (доходы, расходы).  
  - `sqrt` иногда стабилизирует разброс.

**E. Биннинг (интервалы)**
- Разбить непрерывный признак на бины.
- Практически: помогает, если зависимость ступенчатая или модель простая/интерпретируемая.

**F. Внешние данные (join)**
- Добавление справочников, гео-данных, макро-показателей.
- Риск: несовпадение ключей, “грязные” joins, утечка по времени (данные из будущего).

**G. Временные ряды**
- Лаги, разности, скользящие статистики, сезонность.
- Правило: использовать только информацию из прошлого относительно момента предсказания.

---

## 2) Утечки при генерации признаков (экзаменационный must)
**Золотое правило:** все статистики/агрегации, которые “учатся” на данных, считаются как модели:  
**fit только на train**, затем применяем к val/test.

Пример опасного признака:
- “средний таргет по категории” / “средний чек по клиенту” / “среднее по группе id”
Если посчитать по всему датасету — модель подсмотрит тест.

Практический прием:
- Для теста маппить агрегаты, посчитанные **по train**; неизвестные — в глобальную статистику (median/mean).

---

## 3) Скалирование (Scaling)
Скалирование нужно не “всегда”, а **по типу алгоритма**.

### Что выбрать
**1) StandardScaler (Z-score)**
$$
x' = \frac{x - \bar{x}}{\sigma}
$$
- Дефолт для многих задач.
- Хорош для методов, чувствительных к масштабу.

**2) MinMaxScaler**
$$
x' = \frac{x - \min(x)}{\max(x) - \min(x)}
$$
- Когда нужен диапазон [0,1] (часто NN).

**3) RobustScaler**
$$
x' = \frac{x - median}{IQR}
$$
- Если много выбросов: медиана/IQR устойчивее.

### Когда скейлить обязательно
- **Линейные модели с регуляризацией (Ridge/Lasso)**, **SVM**, **KNN**, **PCA**, **нейросети**.

### Когда обычно не нужно
- **Деревья решений, RandomForest, градиентный бустинг по деревьям**: они инвариантны к монотонным преобразованиям масштаба.

### Критическое правило (чтобы не словить leakage)
`scaler.fit(X_train)` → затем `transform` на train/val/test. Никогда наоборот.

---

## 4) Мультиколлинеарность: что это и чем мешает
**Мультиколлинеарность** = признаки сильно линейно зависимы.

### Почему это плохо (на практике)
- Для **линейных моделей**:
  - коэффициенты становятся нестабильными,
  - интерпретация ломается (знаки/величины “скачут”),
  - метрики могут быть норм, но модель “неустойчива”.
- Для **деревьев/бустинга** это обычно менее критично, но может:
  - размывать важности признаков,
  - усложнять интерпретацию.

---

## 5) Как обнаружить мультиколлинеарность
### A. Корреляция Пирсона
$$
r_{xy} = \frac{\sum (x_i - M_x)(y_i - M_y)}{\sqrt{\sum (x_i - M_x)^2 \cdot \sum (y_i - M_y)^2}}
$$
Практическое правило из конспекта: **если \(|r| > 0.7\)** — сильная корреляция.

### B. Корреляционная матрица / heatmap
- Быстро видно “блоки” взаимосвязанных признаков.

### C. VIF (Variance Inflation Factor)
- Более строгий индикатор (часто используют для линейных регрессий).
- Идея: насколько дисперсия коэффициента раздувается из-за корреляций.

### D. Проверка “искусственной” зависимости
- Часто коллинеарность создается самим feature engineering:  
  например, добавили `x`, `2x`, `x+1`, `x/x2` и т.п.

---

## 6) Как бороться с мультиколлинеарностью (рабочие способы)
1) **Удалить один из пары/группы коррелированных**
- Обычно оставляют более интерпретируемый/дешевый/стабильный.

2) **Регуляризация**
- **L2 (Ridge)**: уменьшает коэффициенты, снижает нестабильность.  
- **L1 (Lasso)**: может занулить часть признаков (отбор).

3) **PCA / снижение размерности**
- Убирает корреляции, но ухудшает интерпретацию (признаки становятся компонентами).

4) **Грамотные признаки из domain knowledge**
- Иногда лучше заменить несколько коррелированных столбцов одним смысловым (например, “плотность”, “скорость”, “маржа”).

---

## 7) Мини-чеклист к практике/экзамену
- [ ] Новые признаки добавляю пакетами и проверяю прирост на **валидации**.  
- [ ] Агрегации/groupby считаю **только на train** (иначе утечка).  
- [ ] Скейлер `fit` только на train.  
- [ ] Для линейных моделей проверяю корреляции/VIF и убираю сильные зависимости.  
- [ ] Если делаю One-Hot и линейную модель — слежу за мультиколлинеарностью (dummy trap: `k-1`).  
